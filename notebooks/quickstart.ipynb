{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39932ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to Python path\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab796f03",
   "metadata": {},
   "source": [
    "## 1. Check API Status\n",
    "\n",
    "First, let's check if the API server is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426578b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check API health\n",
    "api_base = \"http://localhost:8000\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{api_base}/health\")\n",
    "    if response.status_code == 200:\n",
    "        health_data = response.json()\n",
    "        print(\"‚úÖ API is healthy!\")\n",
    "        print(f\"Status: {health_data['status']}\")\n",
    "        print(f\"Models loaded: {health_data['models_loaded']}\")\n",
    "        print(f\"Device: {health_data['device']}\")\n",
    "    else:\n",
    "        print(f\"‚ùå API health check failed: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Could not connect to API: {e}\")\n",
    "    print(\"Make sure to run: docker-compose up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e430bca",
   "metadata": {},
   "source": [
    "## 2. Text Generation\n",
    "\n",
    "Test text generation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text generation\n",
    "text_prompt = \"The future of artificial intelligence is\"\n",
    "\n",
    "payload = {\n",
    "    \"prompt\": text_prompt,\n",
    "    \"max_length\": 50,\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{api_base}/text/generate\", json=payload)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"üìù Text Generation Result:\")\n",
    "        print(f\"Prompt: {text_prompt}\")\n",
    "        print(f\"Generated: {result['generated_text']}\")\n",
    "        print(f\"Tokens: {result['tokens_generated']}\")\n",
    "        print(f\"Time: {result['inference_time']:.2f}s\")\n",
    "    else:\n",
    "        print(f\"‚ùå Text generation failed: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ce258",
   "metadata": {},
   "source": [
    "## 3. Text Classification\n",
    "\n",
    "Test text classification with custom labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text classification\n",
    "text_to_classify = \"I love this new technology, it's amazing!\"\n",
    "labels = [\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "params = {\n",
    "    \"text\": text_to_classify,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{api_base}/text/classify\", params=params)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"üè∑Ô∏è Text Classification Result:\")\n",
    "        print(f\"Text: {text_to_classify}\")\n",
    "        print(\"Predictions:\")\n",
    "        for pred in result['predictions']:\n",
    "            print(f\"  {pred['label']}: {pred['score']:.3f}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Text classification failed: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56822576",
   "metadata": {},
   "source": [
    "## 4. Audio Transcription\n",
    "\n",
    "Test audio transcription (you'll need to provide an audio file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple audio file for testing (optional)\n",
    "# This creates a simple sine wave as a test audio file\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import io\n",
    "\n",
    "# Generate a simple test audio (sine wave)\n",
    "duration = 2  # seconds\n",
    "sample_rate = 16000\n",
    "frequency = 440  # A4 note\n",
    "\n",
    "t = np.linspace(0, duration, int(sample_rate * duration))\n",
    "audio_data = 0.3 * np.sin(2 * np.pi * frequency * t)\n",
    "\n",
    "# Save to temporary file\n",
    "temp_audio_path = \"../data/test_audio.wav\"\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "sf.write(temp_audio_path, audio_data, sample_rate)\n",
    "\n",
    "print(f\"‚úÖ Created test audio file: {temp_audio_path}\")\n",
    "print(f\"Duration: {duration}s, Sample rate: {sample_rate}Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test audio transcription\n",
    "audio_file_path = \"../data/test_audio.wav\"\n",
    "\n",
    "if os.path.exists(audio_file_path):\n",
    "    try:\n",
    "        with open(audio_file_path, 'rb') as f:\n",
    "            files = {'file': f}\n",
    "            response = requests.post(f\"{api_base}/audio/transcribe\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(\"üéµ Audio Transcription Result:\")\n",
    "            print(f\"Transcription: '{result['transcription']}'\")\n",
    "            print(f\"Language: {result.get('language', 'unknown')}\")\n",
    "            print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "            print(f\"Time: {result['inference_time']:.2f}s\")\n",
    "        else:\n",
    "            print(f\"‚ùå Audio transcription failed: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå Audio file not found: {audio_file_path}\")\n",
    "    print(\"Please provide an audio file or run the cell above to create a test file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16651a66",
   "metadata": {},
   "source": [
    "## 5. Video Analysis\n",
    "\n",
    "Test video analysis capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da053655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test video (colored frames)\n",
    "import cv2\n",
    "\n",
    "# Create a simple test video with colored frames\n",
    "video_path = \"../data/test_video.mp4\"\n",
    "width, height = 224, 224\n",
    "fps = 5\n",
    "duration = 2  # seconds\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Create frames with different colors\n",
    "colors = [\n",
    "    (255, 0, 0),    # Red\n",
    "    (0, 255, 0),    # Green  \n",
    "    (0, 0, 255),    # Blue\n",
    "    (255, 255, 0),  # Yellow\n",
    "    (255, 0, 255),  # Magenta\n",
    "]\n",
    "\n",
    "for i in range(fps * duration):\n",
    "    color = colors[i % len(colors)]\n",
    "    frame = np.full((height, width, 3), color, dtype=np.uint8)\n",
    "    \n",
    "    # Add some text\n",
    "    cv2.putText(frame, f'Frame {i+1}', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    out.write(frame)\n",
    "\n",
    "out.release()\n",
    "print(f\"‚úÖ Created test video: {video_path}\")\n",
    "print(f\"Frames: {fps * duration}, Duration: {duration}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b986dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test video analysis\n",
    "video_file_path = \"../data/test_video.mp4\"\n",
    "\n",
    "if os.path.exists(video_file_path):\n",
    "    try:\n",
    "        with open(video_file_path, 'rb') as f:\n",
    "            files = {'file': f}\n",
    "            response = requests.post(f\"{api_base}/video/analyze\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(\"üé• Video Analysis Result:\")\n",
    "            print(f\"Description: {result['description']}\")\n",
    "            print(f\"Objects detected: {result['objects']}\")\n",
    "            print(f\"Actions: {result['actions']}\")\n",
    "            print(f\"Time: {result['inference_time']:.2f}s\")\n",
    "        else:\n",
    "            print(f\"‚ùå Video analysis failed: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå Video file not found: {video_file_path}\")\n",
    "    print(\"Please run the cell above to create a test video.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce443b",
   "metadata": {},
   "source": [
    "## 6. Multimodal Chat\n",
    "\n",
    "Test the multimodal chat interface with text, audio, and video inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0cc81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multimodal chat\n",
    "chat_prompt = \"What can you tell me about the content I'm providing?\"\n",
    "\n",
    "# Prepare files\n",
    "files = {}\n",
    "data = {'text_prompt': chat_prompt}\n",
    "\n",
    "# Add audio file if available\n",
    "if os.path.exists(\"../data/test_audio.wav\"):\n",
    "    files['audio_file'] = open(\"../data/test_audio.wav\", 'rb')\n",
    "\n",
    "# Add video file if available\n",
    "if os.path.exists(\"../data/test_video.mp4\"):\n",
    "    files['video_file'] = open(\"../data/test_video.mp4\", 'rb')\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{api_base}/multimodal/chat\", data=data, files=files)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"ü§ñ Multimodal Chat Result:\")\n",
    "        print(f\"User: {chat_prompt}\")\n",
    "        print(f\"Assistant: {result['response']}\")\n",
    "        print(f\"Modalities used: {result['modalities_used']}\")\n",
    "        print(f\"Time: {result['inference_time']:.2f}s\")\n",
    "    else:\n",
    "        print(f\"‚ùå Multimodal chat failed: {response.text}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "finally:\n",
    "    # Close file handles\n",
    "    for file_handle in files.values():\n",
    "        if hasattr(file_handle, 'close'):\n",
    "            file_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f8506",
   "metadata": {},
   "source": [
    "## 7. Performance Summary\n",
    "\n",
    "Let's get a summary of all the tests we ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of capabilities\n",
    "print(\"üéØ Multimodal LLM Capabilities Summary:\")\n",
    "print(\"\" + \"=\"*50)\n",
    "print(\"‚úÖ Text Processing:\")\n",
    "print(\"   - Text generation with controllable parameters\")\n",
    "print(\"   - Text classification with custom labels\")\n",
    "print(\"   - Embedding generation for similarity analysis\")\n",
    "print()\n",
    "print(\"‚úÖ Audio Processing:\")\n",
    "print(\"   - Speech-to-text transcription (Whisper)\")\n",
    "print(\"   - Audio feature extraction\")\n",
    "print(\"   - Multi-language support\")\n",
    "print()\n",
    "print(\"‚úÖ Video Processing:\")\n",
    "print(\"   - Video content analysis and description\")\n",
    "print(\"   - Object detection in video frames\")\n",
    "print(\"   - Action recognition\")\n",
    "print()\n",
    "print(\"‚úÖ Multimodal Integration:\")\n",
    "print(\"   - Cross-modal conversation interface\")\n",
    "print(\"   - Fusion of text, audio, and video inputs\")\n",
    "print(\"   - Context-aware responses\")\n",
    "print()\n",
    "print(\"üöÄ Ready for Development!\")\n",
    "print(\"Next steps:\")\n",
    "print(\"1. Customize models for your specific use case\")\n",
    "print(\"2. Fine-tune on your domain-specific data\")\n",
    "print(\"3. Optimize for your target hardware\")\n",
    "print(\"4. Deploy with appropriate scaling\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
